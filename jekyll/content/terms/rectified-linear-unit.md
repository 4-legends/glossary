---
title: Rectified Linear Unit (ReLU)
---
A Rectified Linear Unit is a common name for a neuron (the "unit")
with an activation function of $f(x) = \max(0,x)$.
